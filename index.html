<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Low-light Image Denoising and Enhancement">
  <meta name="keywords" content="Generative Models, LLIE, Image Denoising, Diffusion Model">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Personalized Generative Low-light Image Denoising and Enhancement</title>
  <style>
    .move-right {
      margin-left: 170px; /* Moves this specific image 100px to the right */
    }
  </style>

<style>
  body {
    font-family: Arial, sans-serif;
    margin: 20px;
    background: #f4f4f4;
  }

  h1 {
    text-align: center;
    margin-bottom: 30px;
  }

</style>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>


  <link rel="stylesheet" href="https://cdn.knightlab.com/libs/juxtapose/latest/css/juxtapose.css">
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 20px;
      background: #f4f4f4;
    }

    h1 {
      text-align: center;
      margin-bottom: 30px;
    }

    /*.juxtapose-container {*/
    /*  width: 90%;*/
    /*  max-width: 1200px;*/
    /*  margin: 20px auto;*/
    /*}*/

    .juxtapose-container {
    width: 100%;
    max-width: 400px;
    height: 400px;
    margin: 20px auto;
    }

    .button.is-selected {
    box-shadow: 0 0 0 2px #444 inset;
    font-weight: bold;
  }

  </style>

<style>
  .switch-case-section {
    margin-top: 10px;
  }

  .case-button {
    border-radius: 12px;
    font-weight: 500;
  }

  .case1 {
    background-color: #f8d7da;
    color: #58151c;
  }

  .case2 {
    background-color: #dbeafe;
    color: #1e3a8a;
  }

  .case3 {
    background-color: #e5d5ea;
    color: #4c3b5f;
  }

  .case-button:hover {
    filter: brightness(0.95);
  }

  .case-note {
    font-size: 1.05rem;
    color: #444;
    margin-top: 5px;
  }
</style>

  <style>
.example-slider-wrapper {
  overflow: hidden;
  width: 100vw;
  max-width: 100vw;
  margin: auto;
}

.example-slider {
  display: flex;
  width: 300vw;  /* 注意这里是 vw 不是 % */
  transition: transform 0.5s ease-in-out;
}

.example-slide {
  width: 100vw;
  flex-shrink: 0;
  min-height: 100vh;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
}

</style>



</head>


<body>
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            <span style="color:#B9770E; font-weight: bold; font-style: italic">Generative Restore</span>
             <br> <!-- 换行 -->
                Personalized Generative Low-light Image Denoising and Enhancement
                 </h1>
          <div class="is-size-5 publication-authors">
            <div class="author-row">
              <span class="author-block">
                <a>Xijun Wang</a>,</span>
              <span class="author-block">
                <a>Prateek Chennuri</a>,</span>
              <span class="author-block">
                <a>Yu Yuan</a>,</span>
              <span class="author-block">
                <a>Bole Ma</a>,</span>
              <span class="author-block">
                <a>Xingguang Zhang</a>,</span>
            </div>
            <div class="author-row">
              <span class="author-block">
                <a>Stanley Chan</a></span>
            </div>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"></sup>Purdue University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2412.14327"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/"
                   class="external-link button is-normal is-rounded is-dark">
              <!-- Code Link. -->
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code(coming)</span>
                  </a>
              </span>
            </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<style>
  /* 全局容器样式 */

  .container {
    width: 90%; /* 内容宽度与屏幕一致 */
    max-width: 1200px; /* 最大宽度限制为1200px，适应大屏 */
    margin: auto; /* 水平居中 */
  }

  table {
    border-collapse: collapse;
    margin: 0 auto;
    width: 100%;
    max-width: 850px;
  }

  table, th, td {
    border: 1.5px solid rgb(230, 230, 230);
  }

  th, td {
    text-align: center;
    vertical-align: middle;
    padding: 5px;
  }

  th {
    font-weight: bold;
    white-space: nowrap;
  }

  /* 固定表格每列宽度 */
  td:first-child {
    width: 8%;
  }

  td:nth-child(2), td:nth-child(3), td:nth-child(4), td:nth-child(5) {
    width: 22%;
  }

  td {
    height: 120px;
  }

  tr:first-child th, tr:first-child td {
    height: 30px; /* 强制限制高度 */
    overflow: hidden; /* 防止内容溢出 */
    line-height: 30px; /* 垂直居中 */
  }

  /* 图片样式 */
  .image-container img {
    width: 110%;
    height: auto;
    max-width: 166px;
    object-fit: contain;
  }
</style>

<section>
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <br>
        <br>
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Modern cameras produce remarkably high-quality images, yet their performance in <strong>low-light</strong> conditions remains
            suboptimal due to fundamental limitations in photon shot noise and sensor read noise. While generative image
            restoration methods have shown promising results compared to traditional approaches, they often suffer from
            hallucinatory content generation when the signal-to-noise ratio (SNR) is low. Leveraging the availability of
            <strong>personalized photo galleries</strong> on users' smartphones, we introduce <strong>Diffusion-based Personalized Generative
            Denoising (DiffPGD)</strong>, a novel approach that builds a customized diffusion model for individual users. Our key
            innovation lies in the development of an <strong>identity-consistent physical buffer</strong> that extracts the physical attributes
            of the person from the gallery. This ID-consistent physical buffer serves as a robust prior that can be seamlessly
            integrated into the diffusion model to restore degraded images without the need for fine-tuning. Over a wide
            range of low-light testing scenarios, we show that DiffPGD achieves superior image denoising and enhancement
            performance compared to existing diffusion-based denoising approaches.

          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Motivation</h2>
        <div class="content has-text-justified">
          <div class="center">
          <img src="./static/images/Figures/concept_fig.png" width="600" height="700" alt="framework" class="move-right">
          </div>
          <p>
            <li>
            <strong>Why Gallery Photos?</strong> Smartphone cameras today store hundreds if not thousands of a user's photos, captured at different times,
            in different places, and under different lighting conditions. While these images have many variations,
            they are all about the <strong>same person(s)</strong>. Therefore, if the imaging goal is to take a photo of this
            user, the <strong>gallery</strong> on the phone would be the best source to build a prior \(p(\mathbf{x})\). The situation is
            summarized in the above Figure. In the context of diffusion-based image restoration, the original
            solution space can be large because many candidate solutions are consistent with the noisy observation.
            The gallery provides a strong constraint to the search problem. This allows us to search for better quality
            images with high precision of the person's identity.
            </li>
            <li>
            <strong>Physical Buffers to the Rescue?</strong> Given the gallery photos, what kind of prior information
            would be useful for restoration? Advancements in computer vision have made it possible to extract detailed
              facial <strong>physical buffers</strong>—including albedo and normal maps—from a person's gallery of images.
              These physical buffers capture crucial identity-defining properties such as surface geometry and skin color,
              effectively encoding an individual's unique identity. At the same time, it
            also eliminates the influence of environmental lighting, pose, and other identity-independent variables. We
            will leverage this rich prior information to improve restoration.
            </li>
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Methods</h2>
<!--        <img src="./static/images/Figures/model_framework.png" alt="Framework">-->

        <figure class="figure">
        <img src="./static/videos/framework.gif" alt="A description of the image", style="max-width:100%; height:auto;">
        <figcaption>The overall architecture of the proposed method. Our core idea is to use ID-consistent physical buffers,
          extracted from gallery photos, to constrain the generative space in the diffusion model restoration process.
          For a high-quality gallery, we use LAP (Zhang et al.) to extract the albedo and normal information for
          each photo and apply adaptive aggregation to fuse the entire gallery. The extracted albedo represents base skin
          color and facial appearance, while normal captures facial geometry. In our framework, the output physical buffers
          isolate the intrinsic ID properties from lighting, shading, and pose, enabling the diffusion model to apply only
          ID-related information consistently.</figcaption>
        </figure>

<!--        <video controls width="1280">-->
<!--        <source src="./static/videos/framework.mov" type="video/mp4">-->
<!--        &lt;!&ndash; 如果有其他格式备用，可添加 &ndash;&gt;-->
<!--        &lt;!&ndash; <source src="./static/videos/slide_animation.webm" type="video/webm"> &ndash;&gt;-->
<!--        &lt;!&ndash; 提示信息：当浏览器不支持video标签或者无法加载视频时会显示 &ndash;&gt;-->
<!--        Your browser does not support the video tag.-->
<!--        </video>-->

        </div>

      </div>
    </div>
    <!--/ Method. -->
</section>


<!-- 滑动视图容器 -->
<div class="example-slider-wrapper">
  <div class="example-slider" id="exampleSlider">

    <!-- Example 1 -->
    <section class="section example-slide" id="example1">
      <div class="container">
        <div class="columns is-multiline">
          <div class="column is-4"><div class="juxtapose-container"><div class="juxtapose" id="slider1"></div></div></div>
          <div class="column is-4"><div class="juxtapose-container"><div class="juxtapose" id="slider2"></div></div></div>
          <div class="column is-4"><div class="juxtapose-container"><div class="juxtapose" id="slider3"></div></div></div>
        </div>
        <div class="columns is-multiline">
          <div class="column is-4"><div class="juxtapose-container"><div class="juxtapose" id="slider4"></div></div></div>
          <div class="column is-4"><div class="juxtapose-container"><div class="juxtapose" id="slider5"></div></div></div>
          <div class="column is-4"><div class="juxtapose-container"><div class="juxtapose" id="slider6"></div></div></div>
        </div>
      </div>
    </section>

    <!-- Example 2 -->
    <section class="section example-slide" id="example2">
      <div class="container">
        <div class="columns is-multiline">
          <div class="column is-4"><div class="juxtapose-container"><div class="juxtapose" id="slider7"></div></div></div>
          <div class="column is-4"><div class="juxtapose-container"><div class="juxtapose" id="slider8"></div></div></div>
          <div class="column is-4"><div class="juxtapose-container"><div class="juxtapose" id="slider9"></div></div></div>
        </div>
        <div class="columns is-multiline">
          <div class="column is-4"><div class="juxtapose-container"><div class="juxtapose" id="slider10"></div></div></div>
          <div class="column is-4"><div class="juxtapose-container"><div class="juxtapose" id="slider11"></div></div></div>
          <div class="column is-4"><div class="juxtapose-container"><div class="juxtapose" id="slider12"></div></div></div>
        </div>
      </div>
    </section>

    <!-- Example 3 -->
    <section class="section example-slide" id="example3">
      <div class="container">
        <div class="columns is-multiline">
          <div class="column is-4"><div class="juxtapose-container"><div class="juxtapose" id="slider13"></div></div></div>
          <div class="column is-4"><div class="juxtapose-container"><div class="juxtapose" id="slider14"></div></div></div>
          <div class="column is-4"><div class="juxtapose-container"><div class="juxtapose" id="slider15"></div></div></div>
        </div>
        <div class="columns is-multiline">
          <div class="column is-4"><div class="juxtapose-container"><div class="juxtapose" id="slider16"></div></div></div>
          <div class="column is-4"><div class="juxtapose-container"><div class="juxtapose" id="slider17"></div></div></div>
          <div class="column is-4"><div class="juxtapose-container"><div class="juxtapose" id="slider18"></div></div></div>
        </div>
      </div>
    </section>

  </div>
</div>



<!-- 滑动视图容器 -->
<div class="has-text-centered switch-case-section">
  <div class="buttons has-addons is-centered case-button-group">
    <button id="btn1" class="button is-medium case-button case1" onclick="showExample('example1')">Example 1</button>
    <button id="btn2" class="button is-medium case-button case2" onclick="showExample('example2')">Example 2</button>
    <button id="btn3" class="button is-medium case-button case3" onclick="showExample('example3')">Example 3</button>
  </div>
  <p class="case-note">Click the buttons above to switch between real-life case examples.</p>
</div>



<script src="https://cdn.knightlab.com/libs/juxtapose/latest/js/juxtapose.min.js"></script>
<script>
  const sliderDataMap = {
    example1: [
      { id: "slider1", before: "./static/images/website/weijian/weijian_input.png", after: "./static/images/website/weijian/ours.png", labelBefore: "Input", labelAfter: "Ours" },
      { id: "slider2", before: "./static/images/website/weijian/weijian_input.png", after: "./static/images/website/weijian/codeformer.png", labelBefore: "Input", labelAfter: "CodeFormer" },
      { id: "slider3", before: "./static/images/website/weijian/weijian_input.png", after: "./static/images/website/weijian/snr_aware.png", labelBefore: "Input", labelAfter: "SNR-aware" },
      { id: "slider4", before: "./static/images/website/weijian/weijian_input.png", after: "./static/images/website/weijian/mirnet.png", labelBefore: "Input", labelAfter: "MIRNet" },
      { id: "slider5", before: "./static/images/website/weijian/weijian_input.png", after: "./static/images/website/weijian/gfpgan.png", labelBefore: "Input", labelAfter: "GFPGAN" },
      { id: "slider6", before: "./static/images/website/weijian/weijian_input.png", after: "./static/images/website/weijian/diffll.png", labelBefore: "Input", labelAfter: "DiffLL" },
    ],
    example2: [
      { id: "slider7", before: "./static/images/website/tharindu/tharindu_input.png", after: "./static/images/website/tharindu/ours.png", labelBefore: "Input", labelAfter: "Ours" },
      { id: "slider8", before: "./static/images/website/tharindu/tharindu_input.png", after: "./static/images/website/tharindu/codeformer.png", labelBefore: "Input", labelAfter: "CodeFormer" },
      { id: "slider9", before: "./static/images/website/tharindu/tharindu_input.png", after: "./static/images/website/tharindu/snr_aware.png", labelBefore: "Input", labelAfter: "SNR-aware" },
      { id: "slider10", before: "./static/images/website/tharindu/tharindu_input.png", after: "./static/images/website/tharindu/mirnet.png", labelBefore: "Input", labelAfter: "MIRNet" },
      { id: "slider11", before: "./static/images/website/tharindu/tharindu_input.png", after: "./static/images/website/tharindu/gfpgan.png", labelBefore: "Input", labelAfter: "GFPGAN" },
      { id: "slider12", before: "./static/images/website/tharindu/tharindu_input.png", after: "./static/images/website/tharindu/diffll.png", labelBefore: "Input", labelAfter: "DiffLL" },
    ],
    example3: [
      { id: "slider13", before: "./static/images/website/kavinga/kavinga_input.png", after: "./static/images/website/kavinga/ours.png", labelBefore: "Input", labelAfter: "Ours" },
      { id: "slider14", before: "./static/images/website/kavinga/kavinga_input.png", after: "./static/images/website/kavinga/codeformer.png", labelBefore: "Input", labelAfter: "CodeFormer" },
      { id: "slider15", before: "./static/images/website/kavinga/kavinga_input.png", after: "./static/images/website/kavinga/snr_aware.png", labelBefore: "Input", labelAfter: "SNR-aware" },
      { id: "slider16", before: "./static/images/website/kavinga/kavinga_input.png", after: "./static/images/website/kavinga/mirnet.png", labelBefore: "Input", labelAfter: "MIRNet" },
      { id: "slider17", before: "./static/images/website/kavinga/kavinga_input.png", after: "./static/images/website/kavinga/gfpgan.png", labelBefore: "Input", labelAfter: "GFPGAN" },
      { id: "slider18", before: "./static/images/website/kavinga/kavinga_input.png", after: "./static/images/website/kavinga/diffll.png", labelBefore: "Input", labelAfter: "DiffLL" },
    ]
  };

  let initializedExamples = {};

  function initJuxtapose(exampleId) {
    if (initializedExamples[exampleId]) return;

    const sliders = sliderDataMap[exampleId];
    sliders.forEach((data) => {
      new juxtapose.JXSlider(`#${data.id}`, [
        { src: data.before, label: data.labelBefore },
        { src: data.after, label: data.labelAfter }
      ], {
        animate: true,
        showLabels: true,
        showCredits: false,
        startingPosition: "30%",
        makeResponsive: true
      });
    });

    initializedExamples[exampleId] = true;
  }

  const exampleIndexMap = {
    example1: 0,
    example2: 1,
    example3: 2
  };

  function showExample(exampleId) {
    const slider = document.getElementById("exampleSlider");
    const index = exampleIndexMap[exampleId] || 0;
    const offset = -index * 100;
    slider.style.transform = `translateX(${offset}vw)`;  // not %
    // 按钮高亮状态（可选）
    ['btn1', 'btn2', 'btn3'].forEach((id, i) => {
      const btn = document.getElementById(id);
      if (btn) {
        btn.classList.toggle("is-selected", index === i);
      }
    });

    // 初始化 Juxtapose（之前加过）
    setTimeout(() => {
      initJuxtapose(exampleId);
      if (window.juxtapose && juxtapose.refresh) {
        juxtapose.refresh();
      }
    }, 200);
  }

  // 初始化默认显示的 Example1
  window.addEventListener('DOMContentLoaded', () => {
    showExample('example1');
  });
</script>





<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{wang2024genrestore,
  title={Personalized Generative Low-light Image Denoising and Enhancement},
  author={Wang, Xijun and Chennuri, Prateek and Yuan, Yu and Ma, Bole and Zhang, Xingguang and Chan, Stanley},
  journal={arXiv preprint arXiv},
  year={2024}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Built with <a
                href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> templates—thanks for their nice jobs!
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>



</body>
</html>
